{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reinitialize the Python interpreter, clearing all variables and imports\n",
    "#%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e8c82",
   "metadata": {},
   "source": [
    "*Configuración global de entorno*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4c72fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno cargado correctamente - listo para Part A, B y C\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# (Importaciones, semilla, estilo)\n",
    "# ============================================================\n",
    "\n",
    "# --- Librerías base ---\n",
    "import os, sys, random, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Scikit-learn (modelos, métricas, CV, etc.) ---\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, KFold, GridSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    f1_score, classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay, mean_squared_error, accuracy_score, zero_one_loss\n",
    ")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Librerías NLP ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# --- Librerías de ISLP (para Carseats) ---\n",
    "from ISLP import load_data\n",
    "\n",
    "# --- Configuración general y reproducibilidad ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# --- Configuración visual de gráficos ---\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# --- Descargas NLTK (solo la primera vez) ---\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# --- Recursos NLP comunes ---\n",
    "stop_en = set(stopwords.words('english'))\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "print(\"Entorno cargado correctamente - listo para Part A, B y C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ff7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8212424",
   "metadata": {},
   "source": [
    "# Part A: Binary Classification on Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ee797",
   "metadata": {},
   "source": [
    "## PASO 1 — Carga del dataset y split 70/30 estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c475376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Buscar el CSV según dónde se ejecute el notebook (raíz o /src)\n",
    "paths = [\"data/disaster_tweets.csv\", \"../data/disaster_tweets.csv\"]\n",
    "csv_path = next((p for p in paths if os.path.exists(p)), None)\n",
    "assert csv_path, \"No se encontró 'data/disaster_tweets.csv'. Verifica la ruta.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "584b9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Cargar y validar columnas requeridas\n",
    "df = pd.read_csv(csv_path)\n",
    "assert {\"text\",\"target\"}.issubset(df.columns), \"Faltan columnas requeridas: 'text' y/o 'target'\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce546049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje target=1 (desastre): 42.97% | target=0: 57.03%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) % de clases\n",
    "y = df[\"target\"].astype(int)\n",
    "X_text = df[\"text\"].astype(str)\n",
    "\n",
    "pct1 = y.mean()*100\n",
    "print(f\"Porcentaje target=1 (desastre): {pct1:.2f}% | target=0: {100-pct1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0b4c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5329 | Test: 2284\n"
     ]
    }
   ],
   "source": [
    "# 4) Split 70/30 estratificado\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_text, y, test_size=0.30, stratify=y, random_state=SEED\n",
    ")\n",
    "print(f\"Train: {len(X_tr)} | Test: {len(X_te)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b05920",
   "metadata": {},
   "source": [
    "## PASO 2-Preprocesamiento (limpieza de texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5208949",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9533a1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "clean",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "596ff191-aa04-4336-bc89-ba081e3ac59d",
       "rows": [
        [
         "0",
         "Las Vegas in top 5 cities for red-light running fatalities http://t.co/kC8O81BcHG",
         "la vega top 5 city red light running fatality"
        ],
        [
         "1",
         "Do you feel like you are sinking in unhappiness? Take the quiz: http://t.co/BTjPEO0Bto http://t.co/ClyJ32L333",
         "feel like sinking unhappiness take quiz"
        ],
        [
         "2",
         "The Architect Behind Kanye WestÛªs Volcano https://t.co/MUSBIk7EJf",
         "architect behind kanye west volcano"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas in top 5 cities for red-light runnin...</td>\n",
       "      <td>la vega top 5 city red light running fatality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you feel like you are sinking in unhappines...</td>\n",
       "      <td>feel like sinking unhappiness take quiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Architect Behind Kanye WestÛªs Volcano ht...</td>\n",
       "      <td>architect behind kanye west volcano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0  Las Vegas in top 5 cities for red-light runnin...   \n",
       "1  Do you feel like you are sinking in unhappines...   \n",
       "2  The Architect Behind Kanye WestÛªs Volcano ht...   \n",
       "\n",
       "                                           clean  \n",
       "0  la vega top 5 city red light running fatality  \n",
       "1        feel like sinking unhappiness take quiz  \n",
       "2            architect behind kanye west volcano  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# PASO 2: PREPROCESAMIENTO\n",
    "# =========================\n",
    "stop_en = set(stopwords.words('english'))\n",
    "lem = WordNetLemmatizer()\n",
    "pat_url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "pat_at  = re.compile(r'@\\w+')\n",
    "\n",
    "def clean_tweet(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = pat_url.sub(' ', s)            # quita URLs\n",
    "    s = pat_at.sub(' ', s)             # quita @menciones\n",
    "    s = re.sub(r'#', ' ', s)           # elimina '#' pero deja la palabra\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s) # quita puntuación/símbolos\n",
    "    toks = [t for t in s.split() if t not in stop_en]\n",
    "    toks = [lem.lemmatize(t) for t in toks]\n",
    "    return \" \".join(toks)\n",
    "\n",
    "X_tr_clean = X_tr.apply(clean_tweet)\n",
    "X_te_clean = X_te.apply(clean_tweet)\n",
    "\n",
    "pd.DataFrame({\"raw\": X_tr.head(3).values, \"clean\": X_tr_clean.head(3).values})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd7719",
   "metadata": {},
   "source": [
    "## PASO 3 — Bag of Words binario (solo fit en train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11e20acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario (unigramas): 1952\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# PASO 3: BoW BINARIO (CountVectorizer)\n",
    "# ==========================================\n",
    "M = 5  # razonable: 3–10. Reduce ruido de términos ultra raros.\n",
    "vec_uni = CountVectorizer(binary=True, min_df=M)\n",
    "\n",
    "Xtr_uni = vec_uni.fit_transform(X_tr_clean)   # fit en train\n",
    "Xte_uni = vec_uni.transform(X_te_clean)       # transform en test\n",
    "\n",
    "print(\"Tamaño del vocabulario (unigramas):\", len(vec_uni.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a38d8",
   "metadata": {},
   "source": [
    "## PASO 4 — Regresión Logística (none, L1, L2) con F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "153698a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR none] F1 train=0.967 | test=0.705\n"
     ]
    }
   ],
   "source": [
    "# (a) Sin regularización (penalty=None en sklearn>=1.4)\n",
    "lr_none = LogisticRegression(penalty=None, solver='lbfgs', max_iter=5000)\n",
    "lr_none.fit(Xtr_uni, y_tr)\n",
    "f1_tr_none = f1_score(y_tr, lr_none.predict(Xtr_uni))\n",
    "f1_te_none = f1_score(y_te, lr_none.predict(Xte_uni))\n",
    "print(f\"[LR none] F1 train={f1_tr_none:.3f} | test={f1_te_none:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7d062bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR L1] best={'C': np.float64(2.5118864315095824)} | F1 train=0.891 | test=0.737\n"
     ]
    }
   ],
   "source": [
    "# (b) L1 con búsqueda de C\n",
    "C_grid = np.logspace(-2, 2, 11)  # 0.01 ... 100\n",
    "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=5000)\n",
    "gs_l1 = GridSearchCV(lr_l1, {\"C\": C_grid}, scoring=\"f1\", cv=cv5, n_jobs=-1)\n",
    "gs_l1.fit(Xtr_uni, y_tr)\n",
    "best_l1 = gs_l1.best_estimator_\n",
    "f1_tr_l1 = f1_score(y_tr, best_l1.predict(Xtr_uni))\n",
    "f1_te_l1 = f1_score(y_te, best_l1.predict(Xte_uni))\n",
    "print(f\"[LR L1] best={gs_l1.best_params_} | F1 train={f1_tr_l1:.3f} | test={f1_te_l1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74dae5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR L2] best={'C': np.float64(0.3981071705534973)} | F1 train=0.838 | test=0.757\n"
     ]
    }
   ],
   "source": [
    "# (c) L2 con búsqueda de C\n",
    "lr_l2 = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
    "gs_l2 = GridSearchCV(lr_l2, {\"C\": C_grid}, scoring=\"f1\", cv=cv5, n_jobs=-1)\n",
    "gs_l2.fit(Xtr_uni, y_tr)\n",
    "best_l2 = gs_l2.best_estimator_\n",
    "f1_tr_l2 = f1_score(y_tr, best_l2.predict(Xtr_uni))\n",
    "f1_te_l2 = f1_score(y_te, best_l2.predict(Xte_uni))\n",
    "print(f\"[LR L2] best={gs_l2.best_params_} | F1 train={f1_tr_l2:.3f} | test={f1_te_l2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8cbfca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1_test",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ba72b023-95f7-4c00-8004-285a4e40b738",
       "rows": [
        [
         "0",
         "LR none",
         "0.9673865138827678",
         "0.7045341305430991"
        ],
        [
         "1",
         "LR L1",
         "0.8914623069936422",
         "0.7370078740157481"
        ],
        [
         "2",
         "LR L2",
         "0.8382075471698113",
         "0.7571428571428571"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR none</td>\n",
       "      <td>0.967387</td>\n",
       "      <td>0.704534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR L1</td>\n",
       "      <td>0.891462</td>\n",
       "      <td>0.737008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR L2</td>\n",
       "      <td>0.838208</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo  F1_train   F1_test\n",
       "0  LR none  0.967387  0.704534\n",
       "1    LR L1  0.891462  0.737008\n",
       "2    LR L2  0.838208  0.757143"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame({\n",
    "    \"Modelo\": [\"LR none\",\"LR L1\",\"LR L2\"],\n",
    "    \"F1_train\": [f1_tr_none, f1_tr_l1, f1_tr_l2],\n",
    "    \"F1_test\":  [f1_te_none, f1_te_l1, f1_te_l2]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b010da",
   "metadata": {},
   "source": [
    "## A.5 Interpretación del modelo L1 (palabras clave)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
